{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The objective of this notebook is to extract features from the information source 2,\n",
    "# which are the technical drawings pdf files located in the local repository\n",
    "# devis_path='C:/..../devis', and to store those features as npz files\n",
    "# in a directory called pdf_path='C:/..../pdf_data'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 350)\n",
    "import numpy as np\n",
    "import sys\n",
    "import glob\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "from shutil import copyfile\n",
    "from pdf2image import convert_from_path\n",
    "from pdf2image.exceptions import PDFInfoNotInstalledError,PDFPageCountError,PDFSyntaxError\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", 'This pattern has match groups')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating variable for path name to the extracted data\n",
    "pdf_path='C:/..../pdf data'\n",
    "\n",
    "# Store this variable for usage in other notebooks\n",
    "%store pdf_path\n",
    "\n",
    "#Getting the stored data back from the original notebooks where the data is generated\n",
    "%store -r devis_path\n",
    "%store -r cpst_path\n",
    "\n",
    "#Checking the variables acctive in the notebook\n",
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this notebook the setup of the credentials must have been performed in PS before opening the notebook\n",
    "#!$env:GOOGLE_APPLICATION_CREDENTIALS='....\\my-project-vision-servaccount.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the API authentification and list the available folders in google storage\n",
    "\n",
    "def implicit():\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # If you don't specify credentials when constructing the client, the\n",
    "    # client library will look for credentials in the environment.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Make an authenticated API request\n",
    "    buckets = list(storage_client.list_buckets())\n",
    "    print(buckets)\n",
    "    \n",
    "implicit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect text in images with Google vision\n",
    "\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "    \n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    ##print('Texts:')\n",
    "    \n",
    "    text_descriptions=[]\n",
    "    text_bounds=[]\n",
    "    \n",
    "    for text in texts:\n",
    "\n",
    "        text_descriptions.append(text.description)\n",
    "        #print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        text_bounds.append(','.join(vertices))\n",
    "        #print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    return text_descriptions, text_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager for reditrecting stdout/err to files\n",
    "\n",
    "class redirect_output(object):\n",
    "    \"\"\"context manager for reditrecting stdout/err to files\"\"\"\n",
    "\n",
    "    def __init__(self, stdout='', stderr=''):\n",
    "        self.stdout = stdout\n",
    "        self.stderr = stderr\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.sys_stdout = sys.stdout\n",
    "        self.sys_stderr = sys.stderr\n",
    "\n",
    "        if self.stdout:\n",
    "            sys.stdout = open(self.stdout, 'w')\n",
    "        if self.stderr:\n",
    "            if self.stderr == self.stdout:\n",
    "                sys.stderr = sys.stdout\n",
    "            else:\n",
    "                sys.stderr = open(self.stderr, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        sys.stdout = self.sys_stdout\n",
    "        sys.stderr = self.sys_stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform image preprocessing\n",
    "# Not yet fully confirmed if this is needed when we use google vision text_detection:\n",
    "# On the tests perform we do not notice a real detection improvement\n",
    "# We keep it nevertheless\n",
    "\n",
    "def image_preprocessing(filepath_in):\n",
    "    \n",
    "    # Getting the image path file\n",
    "    dirname=os.path.dirname(filepath_in)\n",
    "    file_root_name=os.path.splitext(os.path.basename(filepath_in))[0]\n",
    "    file_ext_name=os.path.splitext(os.path.basename(filepath_in))[1]\n",
    "\n",
    "    # Load image, grayscale, Otsu's threshold\n",
    "    image = cv2.imread(filepath_in)\n",
    "    #print(image.shape)\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #print(gray.shape)\n",
    "    \n",
    "    # Blur\n",
    "    blur = cv2.GaussianBlur(gray, (5,5), 5)\n",
    "    #print(thresh.shape)\n",
    "    \n",
    "    thresh = 255 - cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    #print(thresh.shape)\n",
    "    \n",
    "    # Convert back to jpg image\n",
    "    filepath_out = os.path.normpath(os.path.join(dirname,file_root_name+'_pre'+file_ext_name))\n",
    "    cv2.imwrite(filepath_out, thresh)\n",
    "    \n",
    "    return filepath_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert pdf to image\n",
    "\n",
    "dpi=600\n",
    "#size=(None,1600)\n",
    "\n",
    "def convert_pdf_to_image(filepath_in, path_out):\n",
    "    \n",
    "    outputs=[]\n",
    "    \n",
    "    # Generate an image out of the pdf file\n",
    "    ims = convert_from_path(filepath_in, grayscale=True, output_folder=path_out,single_file=True,dpi=dpi,fmt='jpeg',\n",
    "                            jpegopt={'quality': 100,'progressive': True,'optimize': True})\n",
    "    \n",
    "    # Prepare new file name for image with same name as pdf\n",
    "    _,file=os.path.split(os.path.splitext(filepath_in)[0])\n",
    "    print('file:',file)\n",
    "    \n",
    "    # Storing the image grayscale profile (first page)\n",
    "    print('Shape of the image from pdf first page: ',np.shape(np.asarray(ims[0])))\n",
    "    im0_stats=stats.describe(np.asarray(ims[0]).reshape(-1), bias=False, nan_policy='omit')\n",
    "    print('image statistics: ',im0_stats)\n",
    "    \n",
    "    # Save new image as tiff, one image for each pdf page\n",
    "    for i, im in enumerate(ims):\n",
    "               \n",
    "        # Saving image in the pdf folder\n",
    "        im.save(path_out+'{}_page{}from{}.jpg'.format(file,i+1,len(ims)), format='JPEG')\n",
    "        \n",
    "        # Additional saving of image close to the original pdf file\n",
    "        print(os.path.dirname(filepath_in)+'\\\\'+'{}_page{}from{}.jpg'.format(file,i+1,len(ims)))\n",
    "        im.save(os.path.dirname(filepath_in)+'\\\\'+'{}_page{}from{}.jpg'.format(file,i+1,len(ims)), format='JPEG')    \n",
    "        \n",
    "        # return path of the new images\n",
    "        filepath_out = path_out+'{}_page{}from{}.jpg'.format(file,i+1,len(ims))\n",
    "        #filepath_out_1 = os.path.dirname(filepath_in)+'\\\\'+'{}_page{}from{}.jpg'.format(file,i+1,len(ims))\n",
    "    \n",
    "        outputs.append((filepath_out,'{}_page{}from{}.jpg'.format(file,i+1,len(ims))))#,filepath_out_1))\n",
    "    \n",
    "    return outputs, im0_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geometric tolerancing according to:\n",
    "# https://en.wikipedia.org/wiki/Geometric_dimensioning_and_tolerancing\n",
    "# complemented by:\n",
    "# https://docs.julialang.org/en/v1/manual/unicode-input/\n",
    "# https://en.wikipedia.org/wiki/Mathematical_operators_and_symbols_in_Unicode#Characters_in_other_blocks\n",
    "\n",
    "from unicodedata import *\n",
    "import itertools\n",
    "\n",
    "def get_symbols(group):\n",
    "    print([(chr(ord(i)),name(i)) if len(i.encode())>2 else i for i in group],'\\n')\n",
    "\n",
    "groups=[]\n",
    "    \n",
    "# Geometric tolerancing reference chart (per ASME Y14.5 M-1982)\n",
    "form_straightness=['\\U000023E4']\n",
    "form_flatness=['\\U000023E5']\n",
    "form_circularity=['\\U000025CB','\\U000025EF','\\U000026AA','\\U00002B55','\\U0000039F']\n",
    "form_cylindricity=['\\U0000232D']\n",
    "profile_profileofaline=['\\U00002312']\n",
    "profile_profileofasurface=['\\U00002313']\n",
    "orientation_perpendicularity=['\\U000027C2','\\U000022A5']\n",
    "orientation_angularity=['\\U00002220']\n",
    "orientation_parallelism=['\\U00002225','//']\n",
    "orientation_symmetry=['\\U0000232F']\n",
    "location_position=['\\U00002316','\\U00002295','\\U00002A01']\n",
    "location_concentricity=['\\U000025CE','\\U0000229A','\\U000029BE']\n",
    "runout_circularrunout=['\\U00002197']\n",
    "runout_totalrunout=['\\U00002330']\n",
    "\n",
    "# Symbols used in a \"feature control frame\" to specify a feature's description, tolerance, modifier and datum references\n",
    "freestate=['\\U000024BB']\n",
    "least_mat_cond=['\\U000024C1']\n",
    "max_mat_cond=['\\U000024C2']\n",
    "projected_tol_zone=['\\U000024C5']\n",
    "regardless_feature_size=['\\U000024C8']\n",
    "tangent_plane=['\\U000024C9']\n",
    "unequal_bilateral=['\\U000024CA']\n",
    "# Statistical tolerance (ST)\n",
    "# continuous feature (CF)\n",
    "\n",
    "# General tolerance according\n",
    "# https://fr.wikipedia.org/wiki/Tol%C3%A9rances_g%C3%A9n%C3%A9rales\n",
    "general_tolerance=['ISO.?2768']\n",
    "general_tolerance_class=['[fmcv][HKL]']\n",
    "\n",
    "# Holes shaft adjustments\n",
    "holes=['H6','H7','H8','H9','H11']\n",
    "def build_shafts():\n",
    "    shafts=[]\n",
    "    for i in ['c','d','e','f','g','h','js','k','m','p','s','u','x','z']:\n",
    "        for j in ['5','6','7','8','9','11','14']:\n",
    "            shafts.append(i+j)\n",
    "    return shafts\n",
    "shafts=build_shafts()\n",
    "\n",
    "# Signs\n",
    "signs=['\\U000000B1','\\+','-','\\U000000AF','\\U00000304','\\U00000305','\\U00000332','\\U00000336','\\U00002013','\\U00002070',\n",
    "       '\\U0000207A','\\U0000207B','\\U0000207C','\\U00002080','\\U0000208A','\\U0000208B','\\U00002212','\\U00002213',\n",
    "       '\\U00002795','\\U00002796','\\U00002A71','\\U00002A72']\n",
    "\n",
    "# Datums and datum references\n",
    "\n",
    "#def build_ref():\n",
    "#    L=[]\n",
    "#    iterable=['A','B','C','D']#,'E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "#    for a in itertools.permutations(iterable, 1):\n",
    "#        L.append(''.join(a))\n",
    "#    for a in itertools.permutations(iterable, 2):\n",
    "#        L.append(''.join(a))\n",
    "#    for a in itertools.permutations(iterable, 3):\n",
    "#        L.append(''.join(a))\n",
    "#    return L\n",
    "datum=['^\\s[A-Z]{1,3}\\s$']#build_ref()\n",
    "boxes=['\\U00002B1C','\\U000020DE','\\U000025A1','\\U000025FB']\n",
    "#datum feature symbol\n",
    "#datum feature triangle\n",
    "#datum references\n",
    "\n",
    "# Surface finish\n",
    "surface=['^Ra$','^Rz$','^N$']\n",
    "surface_roughness=['^N1$', '^N2$', '^N3$', '^N4$', '^N5$', '^N6$', '^N6$', '^N8$', '^N9$', '^N10$', '^N11$', '^N12$',\n",
    "                   '^Ra.?50$','^Ra.?25$','^Ra.?12.5$','^Ra.?6.3$','^Ra.?3.2$','^Ra.?1.6$','^Ra.?0.8$','^Ra.?0.4$','^Ra.?0.2$','^Ra.?0.1$']\n",
    "\n",
    "\n",
    "# Geometrical features\n",
    "diameter=['\\U000000D8','\\U000000F8','\\U00000278','\\U00002205','\\U00002300']\n",
    "degrees=['°','\\U000000B0','\\U000000BA','\\U0000030A','\\U000025E6','\\U000026AC']\n",
    "radius=['R\\s?\\d[.]?\\d?']\n",
    "unit_inch=['\\d\\\"']\n",
    "\n",
    "#Filtering numbers\n",
    "float_pattern='[-+]?(\\d+([.,]\\d*)?|[.,]\\d+)([eE][-+]?\\d+)?'\n",
    "date=['\\d+[/-]\\d+([/-]\\d+)?']\n",
    "invalid_float=['\\d+\\.\\d+\\.\\d+','[a-zA-Z]+\\d*.?\\d?[a-zA-Z]+','^0\\d']\n",
    "\n",
    "groups=[form_straightness,\n",
    "        form_flatness,\n",
    "        form_circularity,\n",
    "        form_cylindricity,\n",
    "        profile_profileofaline,\n",
    "        profile_profileofasurface,\n",
    "        orientation_perpendicularity,\n",
    "        orientation_angularity,\n",
    "        orientation_parallelism,\n",
    "        orientation_symmetry,\n",
    "        location_position,\n",
    "        location_concentricity,\n",
    "        runout_circularrunout,\n",
    "        runout_totalrunout,\n",
    "        freestate,\n",
    "        least_mat_cond,\n",
    "        max_mat_cond,\n",
    "        projected_tol_zone,\n",
    "        regardless_feature_size,\n",
    "        tangent_plane,\n",
    "        unequal_bilateral,\n",
    "        general_tolerance,general_tolerance_class,\n",
    "        holes, shafts,\n",
    "        signs,\n",
    "        datum,boxes,\n",
    "        surface,surface_roughness,\n",
    "        diameter,degrees,radius,unit_inch, date, invalid_float]\n",
    "\n",
    "groups_names=['form_straightness',\n",
    "        'form_flatness',\n",
    "        'form_circularity',\n",
    "        'form_cylindricity',\n",
    "        'profile_profileofaline',\n",
    "        'profile_profileofasurface',\n",
    "        'orientation_perpendicularity',\n",
    "        'orientation_angularity',\n",
    "        'orientation_parallelism',\n",
    "        'orientation_symmetry',\n",
    "        'location_position',\n",
    "        'location_concentricity',\n",
    "        'runout_circularrunout',\n",
    "        'runout_totalrunout',\n",
    "        'freestate',\n",
    "        'least_mat_cond',\n",
    "        'max_mat_cond',\n",
    "        'projected_tol_zone',\n",
    "        'regardless_feature_size',\n",
    "        'tangent_plane',\n",
    "        'unequal_bilateral',\n",
    "        'general_tolerance','general_tolerance_class',\n",
    "        'holes', 'shafts',\n",
    "        'signs',\n",
    "        'datum','boxes',\n",
    "        'surface','surface_roughness',\n",
    "        'diameter','degrees','radius','unit_inch','date','invalid_float']\n",
    "\n",
    "\n",
    "# Display the symbols\n",
    "for group in groups:\n",
    "    get_symbols(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the list of pdf files to be processed\n",
    "\n",
    "pdf_files = glob.glob(devis_path+'/**/*.pdf', recursive=True)\n",
    "pdf_files[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess step files by batches\n",
    "\n",
    "def get_batch(pdf_files,size):\n",
    "    idx_shuff=np.arange(len(pdf_files))\n",
    "    #np.random.shuffle(idx_shuff)\n",
    "    for i in range(0,len(pdf_files),size):\n",
    "        idx_batch=idx_shuff[i:i+size]\n",
    "        yield [pdf_files[i] for i in idx_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temporary *.pgm files \n",
    "\n",
    "def clean_pgm():\n",
    "    \n",
    "    test = os.listdir(pdf_path)\n",
    "\n",
    "    for item in test:\n",
    "        if item.endswith('.pgm'):\n",
    "            os.remove(os.path.join(pdf_path, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting iteration on the list of pdf files to be processed\n",
    "\n",
    "# Working by batches of files\n",
    "batch_size=1\n",
    "batches=np.int(np.ceil(len(pdf_files)/batch_size))\n",
    "print('batch size: ',batch_size)\n",
    "print('batches: ',batches)\n",
    "skipped_batch=0\n",
    "\n",
    "for batch,pdf_files_batch in enumerate(get_batch(pdf_files, batch_size)):\n",
    "    \n",
    "    print('\\n\\nWorking on batch {} from {} ...'.format(batch+1,batches))\n",
    "    print('Files in batch: ',pdf_files_batch)\n",
    "    \n",
    "    with redirect_output(pdf_path+'/output_{}_from_{}.txt'.format(batch+1,batches)):\n",
    "\n",
    "        # Initialize the dataframe containing variables extracted from step files\n",
    "        df_features=pd.DataFrame()\n",
    "\n",
    "        try:\n",
    "\n",
    "            for pdf_file in pdf_files_batch:\n",
    "\n",
    "                # Initialize a diactionary of variables to be extracted\n",
    "                print('\\n\\nInitializing dictionnary of variables ...')\n",
    "                variables_dict={}\n",
    "\n",
    "                # Define the input pdf location and path for images files to be generated\n",
    "                print(pdf_file)\n",
    "                filepath_in=os.path.abspath(pdf_file)\n",
    "                print('filepath_in: ',filepath_in)\n",
    "                path_out=pdf_path+'/'\n",
    "\n",
    "                # Convert pdf to image\n",
    "                print('Converting pdf to image ...')\n",
    "\n",
    "                outputs,im0_stats=convert_pdf_to_image(filepath_in,path_out)\n",
    "\n",
    "\n",
    "                print('Lenght of the output (i.e. number of pages in pdf) :', len(outputs))\n",
    "\n",
    "\n",
    "                for o,output in enumerate(outputs):\n",
    "\n",
    "                    print('Processing pdf page {} from {}'.format(o+1,len(outputs)))\n",
    "\n",
    "                    filepath_out=output[0]\n",
    "\n",
    "                    print(filepath_out)\n",
    "\n",
    "                    # Add preprocessing to the image            \n",
    "                    filepath_out=image_preprocessing(filepath_out)\n",
    "                    print('Preprocessing the jpg image ...')\n",
    "\n",
    "                    # Detect text in the image with google vision\n",
    "                    print('Proceeding to OCR with google vision on filepath_out :',filepath_out)\n",
    "                    texts, bounds = detect_text(filepath_out)\n",
    "\n",
    "                    # Save image with bounding box\n",
    "                    print('Adding bounding boxes on jpg image ...')\n",
    "                    im=Image.open(filepath_out)\n",
    "                    draw = ImageDraw.Draw(im)\n",
    "                    for bound in bounds:\n",
    "                        draw.polygon(list(eval(bound)), outline='black')\n",
    "                    print('Saving jpg image with bounding boxes at loc1:',filepath_out)\n",
    "                    im.save(filepath_out)\n",
    "\n",
    "                    #Store copy of the file with labels in the original forlder structure for convenience\n",
    "                    print('Saving jpg image with bounding boxes at loc2:',os.path.join(os.path.dirname(filepath_in),os.path.basename(filepath_out)))\n",
    "                    im.save(os.path.join(os.path.dirname(filepath_in),os.path.basename(filepath_out)))\n",
    "                    #copyfile(filepath_out, os.path.dirname(filepath_in))\n",
    "                    #Image.open(filepath_out)\n",
    "\n",
    "                    # Store text data in a dataframe\n",
    "                    print('Storing text data in dataframe ...')\n",
    "                    s_texts=pd.DataFrame(texts, columns=['original'])[1:]\n",
    "\n",
    "                    # Add a column to indicate presence of digits\n",
    "                    print('Adding columns indicating presence of digit in each sequence ...')\n",
    "                    s_texts['has_digit'] = np.where(s_texts['original'].str.contains('\\d'),1,0)\n",
    "\n",
    "                    # Add columns corresponding to the capture groups with float pattern\n",
    "                    print('Adding columns with floats detected in each sequence ...')\n",
    "                    s_texts_digits=s_texts['original'].str.extractall(float_pattern).iloc[:,0].unstack(level=-1)\n",
    "                    s_texts_digits_cols_indexes=list(np.arange(len(s_texts_digits.columns)))\n",
    "                    s_texts=s_texts.join(s_texts_digits, how='left')\n",
    "\n",
    "                    # Add columns corresponding to the capture of all special pattern previously defined\n",
    "                    print('Adding columns with patterns detected in each sequence ...')\n",
    "                    for i,group in enumerate(groups):\n",
    "                        s_texts['{}'.format(group[0])] = np.where(s_texts['original'].str.contains('|'.join(group)),1,0)#'{}'.format()groups_names[i]\n",
    "\n",
    "                    s_texts.rename(columns = {'ISO.?2768':'iso2768',\n",
    "                                              '[fmcv][HKL]':'tol_class',\n",
    "                                              'c5':'shafts',\n",
    "                                              'H6':'holes',\n",
    "                                              '^\\s[A-Z]{1,3}\\s$':'ref',\n",
    "                                              '^Ra$':'Ra',\n",
    "                                              '^N1$':'N',\n",
    "                                              'R\\s?\\d[.]?\\d?':'radius',\n",
    "                                              '\\d\"':'unit_inch',\n",
    "                                              '\\d+[/-]\\d+([/-]\\d+)?':'date',\n",
    "                                              '\\d+\\.\\d+\\.\\d+':'invalid_float'}, inplace=True)\n",
    "\n",
    "                    # Check specific filters\n",
    "                    #s_texts[s_texts.loc[:,'invalid_float']==0]\n",
    "\n",
    "                    # Create a filter for the significative numbers to be extracted\n",
    "                    print('Filtering specific floats ...')\n",
    "                    filter_number=(s_texts['has_digit']==1)\\\n",
    "                                    &(s_texts['date']==0)\\\n",
    "                                    &(s_texts['invalid_float']==0)\n",
    "\n",
    "                    # Put the extracted numbers in a series for further analysis\n",
    "                    s_texts_numbers = pd.to_numeric(s_texts[filter_number][s_texts_digits_cols_indexes].stack(),errors='coerce').dropna().to_frame()\n",
    "\n",
    "                    # Create a filter to remove the points with a non-valid absolute value (taken at 600mm) and a zero value\n",
    "                    filter_outliers_invalid=(s_texts_numbers<600)&(s_texts_numbers!=0)\n",
    "                    s_texts_numbers=s_texts_numbers[filter_outliers_invalid].dropna().copy()\n",
    "                    print(s_texts_numbers)\n",
    "\n",
    "                    # Create a filter to remove the points above a certain distance to average on the positive side\n",
    "                    # We select the mean of the distribution without the datapoints between 0 and 1 which correspond to the tolerancing information\n",
    "                    filter_outliers_zscore=(s_texts_numbers-s_texts_numbers[s_texts_numbers>=1].mean())/s_texts_numbers[s_texts_numbers>=1].std()<4\n",
    "                    s_texts_numbers_filtered_in=s_texts_numbers[filter_outliers_zscore].dropna()\n",
    "                    s_texts_numbers_filtered_out=s_texts_numbers[~filter_outliers_zscore].dropna()\n",
    "                    print(s_texts_numbers_filtered_in)\n",
    "                    print(s_texts_numbers_filtered_out)\n",
    "\n",
    "                    # Create a filter to highlight the lists of points with only integers; this means the drawing contains no float and is probably invalid\n",
    "                    # Such as an assembly drawing with only integers to designate subcomponents\n",
    "                    filter_outliers_allintegers=(s_texts_numbers_filtered_in-s_texts_numbers_filtered_in.apply(np.floor)).sum()\n",
    "\n",
    "                    # Save the digits extracted as txt file for crosschecks\n",
    "                    np.savetxt(filepath_out[:-4]+'.txt', s_texts_numbers_filtered_in, fmt='%.3f')\n",
    "\n",
    "                    # Create a dataframe with the extracted floats\n",
    "                    magnitudes=s_texts_numbers_filtered_in.sum().to_frame().T.drop([0], errors='ignore',axis=1)\n",
    "\n",
    "                    # Split the extracted floats into 2 classes corresponding to the tolerance band and the main dimensions\n",
    "                    tolerance_band_L=[i for i in s_texts_numbers_filtered_in[0] if i<1]\n",
    "                    print(tolerance_band_L)\n",
    "                    dimension_band_L=[i for i in s_texts_numbers_filtered_in[0] if i>=1]\n",
    "                    print(dimension_band_L)\n",
    "                    magnitudes['tolerance_band']=1\n",
    "                    magnitudes['tolerance_band']=magnitudes['tolerance_band'].astype(object)\n",
    "                    magnitudes.at[0, 'tolerance_band'] = tolerance_band_L\n",
    "                    magnitudes['dimension_band']=1\n",
    "                    magnitudes['dimension_band']=magnitudes['dimension_band'].astype(object)\n",
    "                    magnitudes.at[0, 'dimension_band'] = dimension_band_L\n",
    "\n",
    "                    # Store in the dataframe the flag corresponding to the warning for only integers detected\n",
    "                    magnitudes['band_integers_only_warn']=np.where(filter_outliers_allintegers[0]==0,1,0)\n",
    "\n",
    "                    # Store in the dataframe the flag corresponding to the outliers detected in the floats list, number of them and list\n",
    "                    magnitudes['band_outliers_detected']=len(s_texts_numbers_filtered_out)\n",
    "                    magnitudes['band_outliers']=1\n",
    "                    magnitudes['band_outliers']=magnitudes['band_outliers'].astype(object)\n",
    "                    magnitudes.at[0,'band_outliers']=[i for i in s_texts_numbers_filtered_out[0]]\n",
    "\n",
    "                    # Display the full dataframe of the information concerning the extracted floats\n",
    "                    print(magnitudes)\n",
    "\n",
    "                    # Create the dataframe of features available in the drawing\n",
    "                    print('Create the dataframe of features available in the drawing ...')\n",
    "                    #columns_features=['⏤','⏥','○','⌭','⌒','⌓','⟂','∠','∥','⌯','⌖','◎','↗','⌰','Ⓕ','Ⓛ','Ⓜ','Ⓟ','Ⓢ','Ⓣ','Ⓤ',\n",
    "                    #                  'iso2768','tol_class','holes','shafts','±','ref','⬜','Ra','N','Ø','°','radius','unit_inch']\n",
    "                    s_texts_features=s_texts.drop([0,1,2,3,4,5,6,7], errors='ignore',axis=1).set_index('original').astype(int)\n",
    "                    features=s_texts_features.sum(axis=0).to_frame().T\n",
    "\n",
    "                    # Assemble final dataframe\n",
    "                    print('Concatenate final dataframe with all features ...')\n",
    "                    df_feature=pd.concat([magnitudes,features], axis=1)\n",
    "\n",
    "                    # Register the pages informations\n",
    "                    df_feature['pdf_page']=o+1\n",
    "                    df_feature['pdf_pages']=len(outputs)                    \n",
    "\n",
    "                    # Add computed statistics on original image pixels to the main dataframe\n",
    "                    df_feature['im0_stats']=1\n",
    "                    df_feature['im0_stats']=df_feature['im0_stats'].astype(object)\n",
    "                    df_feature.at[0, 'im0_stats'] = list(im0_stats)\n",
    "\n",
    "                    # Register the information on file processed in the dataframe\n",
    "                    path_list=os.path.normpath(pdf_file).split(os.path.sep)\n",
    "                    print(path_list)\n",
    "                    for i in range(len(path_list)):\n",
    "                        df_feature['path_{}'.format(i)]=path_list[i]\n",
    "                    df_feature['file_name']=os.path.basename(pdf_file)\n",
    "                    df_feature['pdf_file']=pdf_file\n",
    "\n",
    "                    df_features=pd.concat([df_features, df_feature], axis=0).reset_index(drop=True)\n",
    "\n",
    "            # Save dataframe as .npz file\n",
    "            print('Save as npz file ...')\n",
    "            np.savez(pdf_path+'/pdf_data_{}_from_{}.npz'.format(batch+1, batches), features=df_features, names=df_features.columns)\n",
    "            print('npz file for this batch generated')\n",
    "\n",
    "        except:\n",
    "            print('Error in batch: current batch skipped.')\n",
    "            skipped_batch+=1\n",
    "        clean_pgm()\n",
    "print('Done')\n",
    "print('Number of batch skipped: ',skipped_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative text detect with local image and language hint\n",
    "```python\n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image,image_context={'language_hints': ['en-t-i0-handwrit']})\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            #print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                #print('Paragraph confidence: {}'.format(\n",
    "                #    paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    #print('Word text: {} (confidence: {})'.format(\n",
    "                    #    word_text, word.confidence))\n",
    "                    \n",
    "                    print(word_text)\n",
    "                    \n",
    "                    #for symbol in word.symbols:\n",
    "                    #    print('\\tSymbol: {} (confidence: {})'.format(\n",
    "                    #        symbol.text, symbol.confidence))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "\n",
    "\n",
    "path_pdf='C:\\\\....\\\\img.jpg'\n",
    "detect_document(path_pdf)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative text detect with local image without language hint\n",
    "```python\n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)#,image_context={'language_hints': ['en-t-i0-handwrit']}\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            #print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                #print('Paragraph confidence: {}'.format(\n",
    "                #    paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    #print('Word text: {} (confidence: {})'.format(\n",
    "                    #    word_text, word.confidence))\n",
    "                    \n",
    "                    print(word_text)\n",
    "                    \n",
    "                    #for symbol in word.symbols:\n",
    "                    #    print('\\tSymbol: {} (confidence: {})'.format(\n",
    "                    #        symbol.text, symbol.confidence))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "\n",
    "\n",
    "path_pdf='C:\\\\....\\\\img.jpg'\n",
    "detect_document(path_pdf)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative text detect with pdf on gs\n",
    "```python\n",
    "def async_detect_document(gcs_source_uri, gcs_destination_uri):\n",
    "    \"\"\"OCR with PDF/TIFF as source files on GCS\"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    from google.cloud import vision\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Supported mime_types are: 'application/pdf' and 'image/tiff'\n",
    "    mime_type = 'application/pdf'\n",
    "\n",
    "    # How many pages should be grouped into each json output file.\n",
    "    batch_size = 1\n",
    "\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "    gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "    input_config = vision.InputConfig(gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "    gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "    output_config = vision.OutputConfig(gcs_destination=gcs_destination, batch_size=batch_size)\n",
    "\n",
    "    async_request = vision.AsyncAnnotateFileRequest(features=[feature], input_config=input_config,output_config=output_config)\n",
    "\n",
    "    operation = client.async_batch_annotate_files(requests=[async_request])\n",
    "\n",
    "    print('Waiting for the operation to finish.')\n",
    "    operation.result(timeout=420)\n",
    "\n",
    "    # Once the request has completed and the output has been\n",
    "    # written to GCS, we can list all the output files.\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    match = re.match(r'gs://([^/]+)/(.+)', gcs_destination_uri)\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # List objects with the given prefix.\n",
    "    blob_list = list(bucket.list_blobs(prefix=prefix))\n",
    "    print('Output files:')\n",
    "    for blob in blob_list:\n",
    "        print(blob.name)\n",
    "\n",
    "    # Process the first output file from GCS.\n",
    "    # Since we specified batch_size=2, the first response contains\n",
    "    # the first two pages of the input file.\n",
    "    output = blob_list[1]\n",
    "\n",
    "    json_string = output.download_as_string()\n",
    "    response = json.loads(json_string)\n",
    "\n",
    "    # The actual response for the first page of the input file.\n",
    "    first_page_response = response['responses'][0]\n",
    "    annotation = first_page_response['fullTextAnnotation']\n",
    "\n",
    "    # Here we print the full text from the first page.\n",
    "    # The response contains more information:\n",
    "    # annotation/pages/blocks/paragraphs/words/symbols\n",
    "    # including confidence scores and bounding boxes\n",
    "    print('Full text:\\n')\n",
    "    print(annotation['text'])\n",
    "\n",
    "    \n",
    "gcs_source_uri='gs://exemple_pdf/doc.pdf'\n",
    "gcs_destination_uri='gs://exemple_pdf/'\n",
    "async_detect_document(gcs_source_uri, gcs_destination_uri)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
